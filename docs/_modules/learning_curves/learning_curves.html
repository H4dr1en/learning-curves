

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>learning_curves.learning_curves &mdash; learning-curves 0.2.3 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> learning-curves
          

          
          </a>

          
            
            
              <div class="version">
                0.2.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html">Welcome to learning-curvesâ€™s documentation!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#installation">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#getting-started">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#custom-predictors">Custom Predictors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#find-the-best-predictor">Find the best Predictor</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#plot-the-predictors">Plot the Predictors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#predictor-bounds">Predictor bounds</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#evaluate-extrapolation-using-mse-validation">Evaluate extrapolation using mse validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#compare-learning-curves-of-various-models">Compare Learning curves of various models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#save-and-load-learningcurve-instances">Save and load LearningCurve instances</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#find-the-best-training-set-size">Find the best training set size</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../intro.html#compare-the-models-performances">Compare the models performances</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../learning_curves.html">Documentation</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">learning-curves</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../index.html">Module code</a> &raquo;</li>
        
      <li>learning_curves.learning_curves</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for learning_curves.learning_curves</h1><div class="highlight"><pre>
<span></span><span class="c1"># coding:utf-8</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">import</span> <span class="nn">gc</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">dill</span>
<span class="kn">import</span> <span class="nn">copy</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="k">import</span> <span class="n">Path</span>

<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="k">import</span> <span class="n">cm</span>
<span class="kn">from</span> <span class="nn">cycler</span> <span class="k">import</span> <span class="n">cycler</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="k">import</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="k">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">ShuffleSplit</span><span class="p">,</span> <span class="n">learning_curve</span>
<span class="kn">import</span> <span class="nn">scipy.optimize</span> <span class="k">as</span> <span class="nn">optimize</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">OptimizeWarning</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">.tools</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">.predictor</span> <span class="k">import</span> <span class="n">Predictor</span>
<span class="kn">from</span> <span class="nn">.monkey_patch</span> <span class="k">import</span> <span class="n">learning_curve_patched</span>


<div class="viewcode-block" id="LearningCurve"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve">[docs]</a><span class="k">class</span> <span class="nc">LearningCurve</span><span class="p">():</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictors</span><span class="o">=</span><span class="p">[],</span> <span class="n">scoring</span><span class="o">=</span><span class="n">r2_score</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Provide helper functions to calculate, plot and fit learning curves. </span>
<span class="sd">    </span>
<span class="sd">            Args:</span>
<span class="sd">                predictors (list): List of Predictors</span>
<span class="sd">                scoring (Callable): Function used to calculate scores of the model. (Default is sklearn r2_score).</span>
<span class="sd">                name (str): Name of the model (used for comparison with other LearningCurve objects).</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">defaults_predictors</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">Predictor</span><span class="p">(</span>  
                        <span class="s2">&quot;pow&quot;</span><span class="p">,</span>        
                        <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span>    <span class="p">:</span> <span class="n">a</span> <span class="o">-</span> <span class="p">(</span><span class="n">b</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">d</span><span class="p">)</span><span class="o">**</span><span class="n">c</span><span class="p">,</span>                  
                        <span class="p">[</span><span class="o">.</span><span class="mi">9</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="o">-.</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> 
                        <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span>    <span class="p">:</span> <span class="p">(</span><span class="o">-</span><span class="n">d</span> <span class="o">+</span> <span class="p">(</span><span class="o">-</span><span class="n">x</span> <span class="o">+</span> <span class="n">a</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">c</span><span class="p">))</span><span class="o">/</span><span class="n">b</span><span class="p">,</span> 
                        <span class="n">bounds</span><span class="o">=</span><span class="p">([</span><span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mf">1e-10</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
                    <span class="p">),</span>

            <span class="n">Predictor</span><span class="p">(</span><span class="s2">&quot;pow_log&quot;</span><span class="p">,</span>    <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="n">d</span><span class="p">,</span> <span class="n">m</span><span class="p">,</span> <span class="n">n</span> <span class="p">:</span> <span class="n">a</span> <span class="o">-</span> <span class="p">(</span><span class="n">b</span><span class="o">*</span><span class="n">x</span><span class="o">+</span><span class="n">d</span><span class="p">)</span><span class="o">**</span><span class="n">c</span> <span class="o">+</span> <span class="n">m</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="n">n</span><span class="p">),</span> <span class="p">[</span><span class="o">.</span><span class="mi">9</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="o">-.</span><span class="mi">5</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">],</span> <span class="n">diverging</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>

            <span class="n">Predictor</span><span class="p">(</span><span class="s2">&quot;pow_log_2&quot;</span><span class="p">,</span>  <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span>       <span class="p">:</span> <span class="n">a</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">b</span><span class="p">))</span><span class="o">**</span><span class="n">c</span><span class="p">),</span>      <span class="p">[</span><span class="o">.</span><span class="mi">9</span><span class="p">,</span> <span class="mf">1.7</span><span class="p">,</span> <span class="o">-.</span><span class="mi">5</span><span class="p">],</span>
                                    <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span>       <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">b</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">a</span> <span class="o">/</span> <span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">c</span><span class="p">)),</span>

            <span class="n">Predictor</span><span class="p">(</span><span class="s2">&quot;inv_log&quot;</span><span class="p">,</span>    <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span>          <span class="p">:</span> <span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="o">/</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">),</span>                 <span class="p">[</span><span class="o">.</span><span class="mi">9</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">],</span>
                                    <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span>         <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">b</span><span class="o">/</span><span class="p">(</span><span class="n">a</span> <span class="o">-</span> <span class="n">x</span><span class="p">))),</span>

            <span class="n">Predictor</span><span class="p">(</span><span class="s2">&quot;exp&quot;</span><span class="p">,</span>        <span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span>       <span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">((</span><span class="n">a</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">+</span><span class="n">b</span><span class="o">/</span><span class="n">x</span> <span class="o">+</span><span class="n">c</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span>  <span class="p">[</span><span class="o">.</span><span class="mi">9</span><span class="p">,</span> <span class="o">-</span><span class="mf">1e3</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">],</span> <span class="n">diverging</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># c = 0 -&gt; convergence</span>
        <span class="p">]</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span> <span class="o">=</span> <span class="n">get_unique_list</span><span class="p">(</span><span class="n">defaults_predictors</span><span class="o">+</span><span class="n">predictors</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span> <span class="o">=</span> <span class="n">scoring</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>


<div class="viewcode-block" id="LearningCurve.save"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.save">[docs]</a>    <span class="k">def</span> <span class="nf">save</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="o">=</span><span class="s2">&quot;./lc_data.pkl&quot;</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Save the LearningCurve object as a pickle object in disk. </span>
<span class="sd">        </span>
<span class="sd">            It uses the dill library to save the instance because the object contains lambda functions, that can not be pickled otherwise.</span>

<span class="sd">            Args:</span>
<span class="sd">                path (str): Path where to save the object. </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">dill</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span></div>


<div class="viewcode-block" id="LearningCurve.get_lc"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.get_lc">[docs]</a>    <span class="k">def</span> <span class="nf">get_lc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">train_kwargs</span><span class="o">=</span><span class="p">{},</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Compute and plot the learning curve. See :meth:`train` and :meth:`plot` functions for parameters.</span>
<span class="sd">        </span>
<span class="sd">            Args:</span>
<span class="sd">                estimator (Object): Must implement a `fit(X,Y)` and `predict(Y)` method.</span>
<span class="sd">                X (array): Features to use for prediction</span>
<span class="sd">                Y (array): Values to be predicted</span>
<span class="sd">                train_kwargs (dict): See :meth:`train` parameters</span>
<span class="sd">                kwargs (dict): See:meth:`plot` parameters.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="o">**</span><span class="n">train_kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="LearningCurve.train"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.train">[docs]</a>    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">train_sizes</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_samples</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Compute the learning curve of an estimator over a dataset.</span>

<span class="sd">            Args:</span>
<span class="sd">                estimator (Object): Must implement a `fit(X,Y)` and `predict(Y)` method.</span>
<span class="sd">                X (array): Features to use for prediction</span>
<span class="sd">                Y (array): Values to be predicted</span>
<span class="sd">                train_sizes (list): See sklearn `learning_curve`_ function documentation. If None, np.geomspace will be used with 20 values from </span>
<span class="sd">                n_split (int): Number of random cross validation calculated for each train size</span>
<span class="sd">                verbose (int): The higher, the more verbose.</span>
<span class="sd">                n_jobs (int): See sklearn `learning_curve`_ function documentation. </span>
<span class="sd">                n_samples (int): if train_sizes is None, n_samples is the number of samples of to use for the learning curve.</span>
<span class="sd">                kwargs (dict): See sklearn `learning_curve`_ function parameters. Invalid parameters raise errors.</span>
<span class="sd">            Returns:</span>
<span class="sd">                Dict: The resulting object can then be passed to :meth:`plot` function.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">train_sizes</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">min_scale</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="p">(</span><span class="o">-</span><span class="n">get_scale</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">train_sizes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">geomspace</span><span class="p">(</span><span class="n">min_scale</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="n">n_samples</span><span class="p">)</span>

        <span class="n">cv</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">)</span>
        <span class="n">t_start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span>
        <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">,</span> <span class="n">fit_times</span><span class="p">,</span> <span class="n">score_times</span> <span class="o">=</span> <span class="n">learning_curve_patched</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="n">n_jobs</span><span class="p">,</span> 
                                                                                    <span class="n">train_sizes</span><span class="o">=</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;total_size&quot;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">),</span>
            <span class="s2">&quot;train_sizes&quot;</span><span class="p">:</span> <span class="n">train_sizes</span><span class="p">,</span>
            <span class="s2">&quot;train_scores_mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="s2">&quot;train_scores_std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="s2">&quot;test_scores_mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="s2">&quot;test_scores_std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">test_scores</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="s2">&quot;times&quot;</span><span class="p">:</span> <span class="n">time</span><span class="o">.</span><span class="n">perf_counter</span><span class="p">()</span> <span class="o">-</span> <span class="n">t_start</span><span class="p">,</span>
            <span class="s2">&quot;fit_times_mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">fit_times</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="s2">&quot;fit_times_std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">fit_times</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="s2">&quot;score_times_mean&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">score_times</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="s2">&quot;score_times_std&quot;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">score_times</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="p">}</span>

        <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span></div>


<div class="viewcode-block" id="LearningCurve.get_predictor"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.get_predictor">[docs]</a>    <span class="k">def</span> <span class="nf">get_predictor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Get a :class:`learning_curves.predictor` from the list of the Predictors.</span>
<span class="sd">            </span>
<span class="sd">            Args:</span>
<span class="sd">                pred (Predictor, str, list): Predictor name, &quot;best&quot; or &quot;all&quot;, a Predictor, a list of string (Predictor names), a list of Predictors`</span>
<span class="sd">            Returns:</span>
<span class="sd">                Predictor, list: The matching Predictor(s)</span>
<span class="sd">            Raises:</span>
<span class="sd">                ValueError: If no matching Predictor is found</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="s2">&quot;best&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_predictor</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">pred</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span>
                <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span> 
            <span class="k">else</span><span class="p">:</span>
                <span class="n">matches</span> <span class="o">=</span> <span class="p">[</span><span class="n">P</span> <span class="k">for</span> <span class="n">P</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span> <span class="k">if</span> <span class="n">P</span><span class="o">.</span><span class="n">name</span> <span class="o">==</span> <span class="n">pred</span><span class="p">]</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">matches</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="k">return</span> <span class="n">matches</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">Predictor</span><span class="p">):</span> <span class="k">return</span> <span class="n">pred</span>

        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">if</span> <span class="s2">&quot;best&quot;</span> <span class="ow">in</span> <span class="n">pred</span> <span class="ow">or</span> <span class="s2">&quot;all&quot;</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;A list of predictors can not contain &#39;best&#39; or &#39;all&#39;.&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">get_predictor</span><span class="p">(</span><span class="n">P</span><span class="p">)</span> <span class="k">for</span> <span class="n">P</span> <span class="ow">in</span> <span class="n">pred</span><span class="p">]</span>
            
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Predictor </span><span class="si">{pred}</span><span class="s2"> could not be found.&quot;</span><span class="p">)</span></div>


<div class="viewcode-block" id="LearningCurve.fit_all"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.fit_all">[docs]</a>    <span class="k">def</span> <span class="nf">fit_all</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Fit a curve with all the predictors using the recorder data and retrieve score if y_pred is finite.</span>

<span class="sd">            Args:                </span>
<span class="sd">                kwargs (dict): Parameters that will be forwarded to internal functions.</span>
<span class="sd">            Returns:</span>
<span class="sd">                list: an array of predictors with the updated params and score.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_all_cust</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;test_scores_mean&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;test_scores_std&quot;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="LearningCurve.fit_all_cust"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.fit_all_cust">[docs]</a>    <span class="k">def</span> <span class="nf">fit_all_cust</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Fit a curve with all the predictors and retrieve score if y_pred is finite.</span>

<span class="sd">            Args:                </span>
<span class="sd">                x (list): 1D array (list) representing the training sizes</span>
<span class="sd">                y (list): 1D array (list) representing the test scores</span>
<span class="sd">            Returns:</span>
<span class="sd">                list: an array of predictors with the updated params and score.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">predictors</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">results</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">))</span>
            <span class="k">except</span> <span class="ne">RuntimeError</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;</span><span class="si">{p.name}</span><span class="s2">: Impossible to fit the learning curve (change initial gess).&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">results</span>  <span class="c1"># [self.fit(p,x,y) for p in self.predictors] # No error handling</span></div>


<div class="viewcode-block" id="LearningCurve.fit"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.fit">[docs]</a>    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Fit a curve with a predictor, compute  and save the score of the fit.</span>

<span class="sd">            Args:                </span>
<span class="sd">                x (list): 1D array (list) representing the training sizes</span>
<span class="sd">                y (list): 1D array (list) representing the test scores</span>
<span class="sd">                kwargs (dict): Parameters that will be forwarded to Scipy curve_fit.</span>
<span class="sd">            Returns:                </span>
<span class="sd">                Predictor: The Predictor with the updated params and score. Score will be None if a ValueError exception occures while computing the score.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">Predictor</span><span class="p">),</span> <span class="s2">&quot;The given Predictor is not a Predictor object.&quot;</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>                
                <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="ne">RuntimeWarning</span><span class="p">)</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">,</span> <span class="n">OptimizeWarning</span><span class="p">)</span>      
                <span class="n">P</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">P</span><span class="o">.</span><span class="n">cov</span> <span class="o">=</span> <span class="n">optimize</span><span class="o">.</span><span class="n">curve_fit</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">P</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">P</span><span class="o">.</span><span class="n">bounds</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>       
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">P</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">P</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scoring</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span>
        <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
            <span class="n">P</span><span class="o">.</span><span class="n">score</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">P</span></div>


<div class="viewcode-block" id="LearningCurve.eval_train_sizes"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.eval_train_sizes">[docs]</a>    <span class="k">def</span> <span class="nf">eval_train_sizes</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Compute the difference of scale between the first and last gradients of accuracies of the train_sizes.</span>

<span class="sd">            If this number is lower than 2, then it indicates that the provided training set sizes don&#39;t cover a wide enough range of the accuracies values</span>
<span class="sd">            to fit a curve. In that case, you should look at the generated plot to determine if you need more points close to the minimum or the maximum training set size.</span>

<span class="sd">            Returns:</span>
<span class="sd">                tain_size_score (float): The difference of scale between the first and last gradients of accuracies of the train_sizes</span>
<span class="sd">            Example:</span>
<span class="sd">                get_train_sizes_grads([   2,    8,  ..., 2599, 2824]) &gt; 2.7156</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Recorder is empty. You must first compute learning curve data points using the train method.&quot;</span><span class="p">)</span>
        
        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">]</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;train_sizes must have at least 4 values&quot;</span>

        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_predictor</span><span class="p">()(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">grad_low</span>  <span class="o">=</span> <span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>    <span class="o">/</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span><span class="n">X</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">grad_high</span> <span class="o">=</span> <span class="p">(</span><span class="n">Y</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">Y</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>   <span class="o">/</span> <span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">-</span><span class="n">X</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">get_scale</span><span class="p">(</span><span class="n">grad_low</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-</span> <span class="n">get_scale</span><span class="p">(</span><span class="n">grad_high</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span></div>


<div class="viewcode-block" id="LearningCurve.eval_fitted_curve"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.eval_fitted_curve">[docs]</a>    <span class="k">def</span> <span class="nf">eval_fitted_curve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">validation</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Split the data points in two sets then fit predictors in the first set and evaluate them using RMSE on the second set. See :meth:`eval_fitted_curve_cust` </span>

<span class="sd">            Args:</span>
<span class="sd">                validation (float, int): Percentage or number of samples of the validation set (the highest training sizes will be used for validation (extrapolation)).</span>
<span class="sd">                kwargs (dict): Parameters passed to :meth:`eval_fitted_curve_cust`</span>
<span class="sd">            Returns:</span>
<span class="sd">                fit_score (float): The Root Mean Squared Error of the validation set against the fitted curve of the Predictor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Recorder is empty. You must first compute learning curve data points using the train method.&quot;</span><span class="p">)</span>
        
        <span class="n">valid_abs</span> <span class="o">=</span> <span class="n">get_absolute_value</span><span class="p">(</span><span class="n">validation</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">]))</span>
        <span class="n">train_sizes_val</span>      <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">][</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">:]</span>
        <span class="n">test_scores_mean_val</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;test_scores_mean&quot;</span><span class="p">][</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">:]</span>
        <span class="n">train_sizes_fit</span>      <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">]</span>
        <span class="n">test_scores_mean_fit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;test_scores_mean&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">]</span>
        <span class="n">test_scores_std_fit</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;test_scores_std&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">]</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_fitted_curve_cust</span><span class="p">(</span><span class="n">train_sizes_fit</span><span class="p">,</span> <span class="n">test_scores_mean_fit</span><span class="p">,</span> <span class="n">test_scores_std_fit</span><span class="p">,</span> <span class="n">train_sizes_val</span><span class="p">,</span> <span class="n">test_scores_mean_val</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="LearningCurve.eval_fitted_curve_cust"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.eval_fitted_curve_cust">[docs]</a>    <span class="k">def</span> <span class="nf">eval_fitted_curve_cust</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_sizes_fit</span><span class="p">,</span> <span class="n">test_scores_mean_fit</span><span class="p">,</span> <span class="n">test_scores_std_fit</span><span class="p">,</span> <span class="n">train_sizes_val</span><span class="p">,</span> <span class="n">test_scores_mean_val</span><span class="p">,</span> <span class="n">predictor</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Compute the RMSE of of a fitted curve over a validation set.</span>

<span class="sd">            Args:</span>
<span class="sd">                train_sizes_fit (array): List of train sizes used for the fitting of the curve</span>
<span class="sd">                test_scores_mean_fit (array): Means computed by the estimator for the train sizes.</span>
<span class="sd">                test_scores_std_fit (array): Standard deviations computed by the estimator for the train sizes.</span>
<span class="sd">                train_sizes_val (array): List of train sizes used for vscoring of the fitting of the curve (the computation of the RMSE).</span>
<span class="sd">                test_scores_mean_val (array): Values computed by the estimator for the validation train sizes.</span>
<span class="sd">                predictor (Predictor, &quot;best&quot;): Predictor to consider</span>
<span class="sd">                fit (bool): If True, perform a fit of the Predictors using the test_scores_mean_fit data points.</span>
<span class="sd">            Returns:</span>
<span class="sd">                fit_score (float): The Root Mean Squared Error of the validation set against the fitted curve of the Predictor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">predictor</span> <span class="o">==</span> <span class="s2">&quot;best&quot;</span><span class="p">:</span> 
            <span class="n">predictors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictor</span><span class="p">,</span> <span class="n">Predictor</span><span class="p">):</span>
            <span class="n">predictors</span> <span class="o">=</span> <span class="p">[</span><span class="n">predictor</span><span class="p">]</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;predictor parameter must be a list of Predictors or &#39;best&#39;.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">fit</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">fit_all_cust</span><span class="p">(</span><span class="n">train_sizes_fit</span><span class="p">,</span> <span class="n">test_scores_mean_fit</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">test_scores_std_fit</span><span class="p">)</span>

        <span class="n">P</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_predictor</span><span class="p">(</span><span class="n">predictors</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test_scores_mean_val</span><span class="p">,</span> <span class="n">P</span><span class="p">(</span><span class="n">train_sizes_val</span><span class="p">))</span> <span class="o">**</span><span class="mf">0.5</span></div>


<div class="viewcode-block" id="LearningCurve.threshold"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.threshold">[docs]</a>    <span class="k">def</span> <span class="nf">threshold</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">P</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; See :meth:`threshold_cust` function. This function calls :meth:`threshold_cust` with the recorder data.</span>

<span class="sd">            Args:</span>
<span class="sd">                P (Predictor, string): Predictor to use.</span>
<span class="sd">                kwargs (dict): Parameters that will be forwarded to internal functions.</span>
<span class="sd">            Returns:</span>
<span class="sd">                Tuple: (x_thresh, y_thresh, sat_val, threshold). If P is diverging, the saturation value will be 1.</span>
<span class="sd">            Raises:</span>
<span class="sd">                RuntimeError: If the recorder is empty.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;Recorder is empty. You must first compute learning curve data points using the train method.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="p">:</span> <span class="n">P</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_predictor</span><span class="p">(</span><span class="n">P</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_cust</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="LearningCurve.threshold_cust"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.threshold_cust">[docs]</a>    <span class="k">def</span> <span class="nf">threshold_cust</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.99</span><span class="p">,</span> <span class="n">max_scaling</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mf">1e4</span><span class="p">,</span> <span class="n">strategies</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">max_scaling</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=-</span><span class="mf">0.01</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Find the training set size providing the highest accuracy up to a predefined threshold. </span>

<span class="sd">            P(x) = y and for x -&gt; inf, y -&gt; saturation value. This method approximates x_thresh such as P(x_thresh) = threshold * saturation value. </span>

<span class="sd">            Args:</span>
<span class="sd">                P (str, Predictor): The predictor to use for the calculation of the saturation value.    </span>
<span class="sd">                x (array): Training set sizes</span>
<span class="sd">                threshold (float): In [0.0, 1.0]. Percentage of the saturation value to use for the calculus of the best training set size.</span>
<span class="sd">                max_scaling (float): Order of magnitude added to the order of magnitude of the maximum train set size. Generally, a value of 1-2 is enough.</span>
<span class="sd">                resolution (float): Only considered for diverging Predictors without inverse function. The higher it is, the more accurate the value of the training set size will be.</span>
<span class="sd">                strategies (dict): A dictionary of the values to add / substract to the other parameters in case a saturation value can not be found.</span>
<span class="sd">                    If an RecursionError raises, (None, None, sat_val, threshold) will be returned.</span>
<span class="sd">                kwargs (dict): Parameters that will be forwarded to internal functions.</span>
<span class="sd">            Returns:</span>
<span class="sd">                Tuple: (x_thresh, y_thresh, saturation_arrucacy, threshold)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_cust_inv</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">threshold</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">inv</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_cust_approx</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="n">x</span><span class="p">,</span><span class="n">threshold</span><span class="p">,</span> <span class="n">max_scaling</span><span class="p">,</span> <span class="n">resolution</span><span class="p">,</span> <span class="n">strategies</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>         </div>


<div class="viewcode-block" id="LearningCurve.threshold_cust_inv"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.threshold_cust_inv">[docs]</a>    <span class="k">def</span> <span class="nf">threshold_cust_inv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Find the training set size providing the highest accuracy up to a desired threshold for a Predictor having an inverse function. See :meth:`threshold_cust`. &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">callable</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">inv</span><span class="p">),</span> <span class="s2">&quot;P has no inverse function. You have to call threshold_cust_approx instead.&quot;</span>
        <span class="k">assert</span> <span class="n">threshold</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">,</span> <span class="s2">&quot;No threshold value&quot;</span>

        <span class="n">sat_acc</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">get_saturation</span><span class="p">()</span>
        <span class="n">desired_acc</span> <span class="o">=</span> <span class="n">sat_acc</span> <span class="o">*</span> <span class="n">threshold</span>            
        <span class="n">opt_trn_size</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">desired_acc</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">opt_trn_size</span><span class="p">):</span> <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">sat_acc</span><span class="p">,</span> <span class="n">threshold</span>

        <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">opt_trn_size</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">desired_acc</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">sat_acc</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">threshold</span></div>


<div class="viewcode-block" id="LearningCurve.threshold_cust_approx"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.threshold_cust_approx">[docs]</a>    <span class="k">def</span> <span class="nf">threshold_cust_approx</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">threshold</span><span class="p">,</span> <span class="n">max_scaling</span><span class="p">,</span> <span class="n">resolution</span><span class="p">,</span> <span class="n">strategies</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Find the training set size providing the highest accuracy up to a predefined threshold for a Predictor having no inverse function. See :meth:`threshold_cust`. &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="kc">None</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="n">threshold</span><span class="p">,</span> <span class="n">max_scaling</span><span class="p">,</span> <span class="n">resolution</span><span class="p">],</span> <span class="s2">&quot;Parameter has None value&quot;</span>

        <span class="n">sat_acc</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">get_saturation</span><span class="p">()</span>
        <span class="n">desired_acc</span> <span class="o">=</span> <span class="n">sat_acc</span> <span class="o">*</span> <span class="n">threshold</span>

        <span class="n">x_max_scale</span> <span class="o">=</span> <span class="n">get_scale</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">max_val</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">**</span> <span class="p">(</span><span class="n">x_max_scale</span> <span class="o">+</span> <span class="n">max_scaling</span><span class="p">)</span>
        <span class="n">num_splits</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">resolution</span><span class="p">,</span> <span class="n">max_val</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">max_val</span><span class="p">,</span> <span class="n">num_splits</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uintc</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">P</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isfinite</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span> <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">sat_acc</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">threshold</span>

        <span class="c1"># If Predictor is a decreasing function, stop computing: there is no solution.</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">is_strictly_increasing</span><span class="p">(</span><span class="n">y</span><span class="p">):</span> <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">sat_acc</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">threshold</span>

        <span class="n">i</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span> <span class="o">&gt;=</span> <span class="n">desired_acc</span><span class="p">)</span>

        <span class="c1"># if not enough values in x to find an x_thresh, apply strategies to adjust parameters</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">strategies</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> 
                <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">max_scaling</span><span class="o">=</span><span class="n">max_scaling</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="n">resolution</span><span class="p">)</span>
                <span class="n">params</span> <span class="o">=</span> <span class="n">update_params</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">strategies</span><span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">threshold_cust_approx</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">strategies</span><span class="o">=</span><span class="n">strategies</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">)</span>
                <span class="k">except</span> <span class="n">RecursionError</span><span class="p">:</span>
                    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">sat_acc</span><span class="p">,</span> <span class="n">threshold</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">sat_acc</span><span class="p">,</span> <span class="n">threshold</span>
        
        <span class="k">else</span><span class="p">:</span>
            <span class="n">opt_trn_size</span><span class="p">,</span> <span class="n">opt_acc</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">opt_trn_size</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">opt_acc</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">sat_acc</span><span class="p">,</span><span class="mi">4</span><span class="p">),</span> <span class="n">threshold</span></div>


<div class="viewcode-block" id="LearningCurve.best_predictor"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.best_predictor">[docs]</a>    <span class="k">def</span> <span class="nf">best_predictor</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictors</span><span class="o">=</span><span class="s2">&quot;all&quot;</span><span class="p">,</span> <span class="n">prefer_conv_delta</span><span class="o">=</span><span class="mf">2e-3</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Find the Predictor having the best fit of a learning curve. </span>
<span class="sd">        </span>
<span class="sd">            Args:</span>
<span class="sd">                predictors (list(Predictor), &quot;all&quot;): A list of Predictors to consider.</span>
<span class="sd">                prefer_conv_delta (float): If the difference of the two best Predictor fit scores is lower than prefer_conv_delta, then if the converging Predict will be prefered (if any).</span>
<span class="sd">                kwargs (dict): Parameters that will be forwarded to internal functions.</span>
<span class="sd">            Returns:</span>
<span class="sd">                Predictor: The Predicto having the best fit of the learning curve.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">predictors</span> <span class="o">==</span> <span class="s2">&quot;all&quot;</span><span class="p">:</span> <span class="n">predictors</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span>

        <span class="n">best_p</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">for</span> <span class="n">P</span> <span class="ow">in</span> <span class="n">predictors</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">P</span><span class="o">.</span><span class="n">score</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="k">continue</span>
            <span class="k">if</span> <span class="n">best_p</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">best_p</span> <span class="o">=</span> <span class="n">P</span> 
            <span class="k">elif</span> <span class="n">P</span><span class="o">.</span><span class="n">score</span> <span class="o">+</span> <span class="n">prefer_conv_delta</span> <span class="o">&gt;=</span> <span class="n">best_p</span><span class="o">.</span><span class="n">score</span><span class="p">:</span> 
                <span class="k">if</span> <span class="n">P</span><span class="o">.</span><span class="n">diverging</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">best_p</span><span class="o">.</span><span class="n">diverging</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">P</span><span class="o">.</span><span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_p</span><span class="o">.</span><span class="n">score</span><span class="p">:</span> <span class="n">best_p</span> <span class="o">=</span> <span class="n">P</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">P</span><span class="o">.</span><span class="n">score</span> <span class="o">-</span> <span class="n">prefer_conv_delta</span> <span class="o">&gt;</span> <span class="n">best_p</span><span class="o">.</span><span class="n">score</span><span class="p">:</span> <span class="n">best_p</span> <span class="o">=</span> <span class="n">P</span>
                <span class="k">else</span><span class="p">:</span>                    
                    <span class="k">if</span> <span class="n">best_p</span><span class="o">.</span><span class="n">diverging</span><span class="p">:</span> <span class="n">best_p</span> <span class="o">=</span> <span class="n">P</span>
                    <span class="k">elif</span> <span class="n">P</span><span class="o">.</span><span class="n">score</span> <span class="o">&gt;</span> <span class="n">best_p</span><span class="o">.</span><span class="n">score</span><span class="p">:</span> <span class="n">best_p</span> <span class="o">=</span> <span class="n">P</span>
        <span class="k">return</span> <span class="n">best_p</span></div>


<div class="viewcode-block" id="LearningCurve.plot"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.plot">[docs]</a>    <span class="k">def</span> <span class="nf">plot</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Plot the training and test learning curves of the recorder data, with optionally fitted functions and saturation. See :meth:`plot_cust`:</span>

<span class="sd">            Args:</span>
<span class="sd">                predictor (str, list(str), Predictor, list(Predictor)): The predictor(s) to use for plotting the fitted curve. Can also be &quot;all&quot; and &quot;best&quot;.</span>
<span class="sd">                figsize (2uple): Size of the figure</span>
<span class="sd">                kwargs (dict): Parameters that will be forwarded to internal functions.</span>
<span class="sd">            Returns:</span>
<span class="sd">                A Matplotlib figure of the result.</span>
<span class="sd">            Raises:</span>
<span class="sd">                RuntimeError: If the recorder is empty.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;recorder is empty. You must first compute learning curve data points using the train method.&quot;</span><span class="p">)</span>

        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
        <span class="n">colors</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;axes.prop_cycle&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">by_key</span><span class="p">()[</span><span class="s1">&#39;color&#39;</span><span class="p">]</span>
        <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">colors</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">colors</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span> <span class="o">+</span> <span class="n">colors</span> <span class="c1"># learning curve of training set in blue, of validation set in green</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="s1">&#39;color&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_cust</span><span class="p">(</span><span class="n">predictor</span><span class="o">=</span><span class="n">predictor</span><span class="p">,</span> <span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>


<div class="viewcode-block" id="LearningCurve.plot_cust"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.plot_cust">[docs]</a>    <span class="k">def</span> <span class="nf">plot_cust</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span><span class="p">,</span> <span class="n">train_scores_std</span><span class="p">,</span> <span class="n">test_scores_mean</span><span class="p">,</span> <span class="n">test_scores_std</span><span class="p">,</span>
                  <span class="n">predictor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">what</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">xlim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ylim</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">saturation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                  <span class="n">target</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">validation</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">close</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">uncertainty</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">fig</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Plot any training and test learning curves, with optionally fitted functions and saturation.</span>
<span class="sd">        </span>
<span class="sd">            Args:</span>
<span class="sd">                train_sizes (list): Training sizes (x values).</span>
<span class="sd">                train_scores_std (list): Train score standard deviations.</span>
<span class="sd">                test_scores_mean (list): Test score means(y values).</span>
<span class="sd">                test_scores_std (list): Train score means.</span>
<span class="sd">                predictor (str, list(str), Predictor, list(Predictor)): The predictor(s) to use for plotting the fitted curve. Can be &quot;all&quot; or &quot;best&quot;.</span>
<span class="sd">                what (&quot;train&quot;, &quot;valid&quot;, &quot;both&quot;): learning curves to show</span>
<span class="sd">                xlim (2uple): Limits of the x axis of the plot.</span>
<span class="sd">                ylim (2uple): Limits of the y axis of the plot.</span>
<span class="sd">                figsize (2uple): Size of the figure</span>
<span class="sd">                title (str): Title of the figure</span>
<span class="sd">                saturation (str, list(str), Predictor, list(Predictor)): Predictor(s) to consider for displaying the saturation on the plot. Can be &quot;all&quot; or &quot;best&quot;.</span>
<span class="sd">                target (int): Training size to reach. The training size axis will be extended and the fitted curve extrapolated until reaching this value.</span>
<span class="sd">                validation (float): Percentage or number of data points to keep for validation of the curve fitting (they will not be used during the fitting but displayed afterwards)</span>
<span class="sd">                close (bool): If True, close the figure before returning it. This is usefull if a lot of plots are being created because Matplotlib won&#39;t close them, potentially leading to warnings.</span>
<span class="sd">                    If False, the plot will not be closed. This can be desired when working on Jupyter notebooks, so that the plot will be rendered in the output of the cell.</span>
<span class="sd">                uncertainty (bool): If True, plot the standard deviation of the best fitted curve for the validation data points.</span>
<span class="sd">                fig (Matplotlib.figure): A figure on which the learning curve will be drawn. If None, a new one is created.</span>
<span class="sd">                kwargs (dict): Parameters that will be forwarded to internal functions.</span>
<span class="sd">            Returns:</span>
<span class="sd">                fig (Matplotlib.figure)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span> <span class="k">if</span> <span class="n">fig</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">(</span><span class="n">fig</span><span class="p">,</span> <span class="n">fig</span><span class="o">.</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">if</span> <span class="s1">&#39;title&#39;</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Training size&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Estimator score&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

        <span class="n">max_train_size</span> <span class="o">=</span> <span class="n">train_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mf">1.05</span> <span class="c1"># Extend a bit so that the curves don&#39;t stop before the last points.</span>

        <span class="k">if</span> <span class="n">validation</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">valid_abs</span> <span class="o">=</span> <span class="n">get_absolute_value</span><span class="p">(</span><span class="n">validation</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">))</span>
            <span class="n">train_sizes_val</span><span class="p">,</span> <span class="n">test_scores_mean_val</span><span class="p">,</span> <span class="n">test_scores_std_val</span> <span class="o">=</span> \
                <span class="n">train_sizes</span><span class="p">[</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">:],</span> <span class="n">test_scores_mean</span><span class="p">[</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">:],</span> <span class="n">test_scores_std</span><span class="p">[</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">:]</span>

            <span class="n">train_sizes_fit</span><span class="p">,</span> <span class="n">test_scores_mean_fit</span><span class="p">,</span> <span class="n">test_scores_std_fit</span> <span class="o">=</span> \
                <span class="n">train_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">],</span> <span class="n">test_scores_mean</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">],</span> <span class="n">test_scores_std</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="n">valid_abs</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">train_sizes_fit</span><span class="p">,</span> <span class="n">test_scores_mean_fit</span><span class="p">,</span> <span class="n">test_scores_std_fit</span> <span class="o">=</span> <span class="n">train_sizes</span><span class="p">,</span> <span class="n">test_scores_mean</span><span class="p">,</span> <span class="n">test_scores_std</span>

        
        <span class="c1"># Plot the learning curve of training and validation sets</span>
        <span class="k">if</span> <span class="n">what</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;both&quot;</span><span class="p">]:</span>
            <span class="n">lines</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_label</span><span class="p">(</span><span class="s2">&quot;Training score&quot;</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">,</span> <span class="n">train_scores_mean</span> <span class="o">-</span> <span class="n">train_scores_std</span><span class="p">,</span> <span class="n">train_scores_mean</span> <span class="o">+</span> <span class="n">train_scores_std</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_color</span><span class="p">(),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">what</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;valid&quot;</span><span class="p">,</span> <span class="s2">&quot;both&quot;</span><span class="p">]:</span>
            <span class="c1">#ax.plot(train_sizes, test_scores_mean, &#39;o-&#39;, color=&quot;g&quot;, label=self.get_label(&quot;Cross-validation score&quot;))</span>
            <span class="n">errorbar</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">train_sizes_fit</span><span class="p">,</span> <span class="n">test_scores_mean_fit</span><span class="p">,</span> <span class="n">test_scores_std_fit</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_label</span><span class="p">(</span><span class="s2">&quot;Cross-validation score&quot;</span><span class="p">),</span> <span class="n">elinewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes_fit</span><span class="p">,</span> <span class="n">test_scores_mean_fit</span> <span class="o">-</span> <span class="n">test_scores_std_fit</span><span class="p">,</span> <span class="n">test_scores_mean_fit</span> <span class="o">+</span> <span class="n">test_scores_std_fit</span><span class="p">,</span> 
                        <span class="n">color</span><span class="o">=</span><span class="n">errorbar</span><span class="o">.</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_color</span><span class="p">(),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>      


        <span class="c1"># Get the list of Predictors to consider</span>
        <span class="n">predictors_to_fit</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">if</span> <span class="n">predictor</span> <span class="o">==</span> <span class="s2">&quot;best&quot;</span><span class="p">:</span> <span class="n">predictors_to_fit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predictors</span> <span class="c1"># If &quot;best&quot;, wait for fit_all before retrieving the best Predictor</span>

        <span class="k">elif</span> <span class="n">predictor</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> 
            <span class="n">to_add</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_predictor</span><span class="p">(</span><span class="n">predictor</span><span class="p">)</span>
            <span class="n">predictors_to_fit</span> <span class="o">+=</span> <span class="n">to_add</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">to_add</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">to_add</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">saturation</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">saturation</span> <span class="o">!=</span> <span class="s2">&quot;best&quot;</span><span class="p">:</span> <span class="c1"># If &quot;best&quot;, wait for fit_all before retrieving the best Predictor</span>
            <span class="n">saturation</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_predictor</span><span class="p">(</span><span class="n">saturation</span><span class="p">)</span>
            <span class="n">predictors_to_fit</span> <span class="o">+=</span> <span class="n">saturation</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">saturation</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="p">[</span><span class="n">saturation</span><span class="p">]</span>

        <span class="c1"># Fitting Predictors</span>
        <span class="n">predictors_to_fit</span> <span class="o">=</span> <span class="n">get_unique_list</span><span class="p">(</span><span class="n">predictors_to_fit</span><span class="p">)</span> <span class="c1"># Remove duplicates</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_all_cust</span><span class="p">(</span><span class="n">train_sizes_fit</span><span class="p">,</span> <span class="n">test_scores_mean_fit</span><span class="p">,</span> <span class="n">predictors_to_fit</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">test_scores_std_fit</span><span class="p">)</span>
        <span class="n">best_p</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">best_predictor</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">target</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">max_abs</span> <span class="o">=</span> <span class="n">target</span> <span class="k">if</span> <span class="n">target</span> <span class="o">&gt;</span> <span class="n">max_train_size</span> <span class="k">else</span> <span class="n">max_train_size</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#1f77b4&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">max_abs</span> <span class="o">=</span> <span class="n">max_train_size</span>

        <span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">train_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">max_abs</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>

        <span class="c1"># Plot fitted curves</span>
        <span class="n">preds_to_plot</span> <span class="o">=</span> <span class="p">[</span><span class="n">P</span> <span class="k">for</span> <span class="n">P</span> <span class="ow">in</span> <span class="n">predictors_to_fit</span> <span class="k">if</span> <span class="n">P</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">P</span><span class="o">.</span><span class="n">score</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">score</span><span class="p">)]</span> <span class="k">if</span> <span class="n">predictor</span> <span class="o">!=</span> <span class="s2">&quot;best&quot;</span> <span class="k">else</span> <span class="p">[</span><span class="n">best_p</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">P</span> <span class="ow">in</span> <span class="n">preds_to_plot</span><span class="p">:</span>
            <span class="n">best_lbl</span> <span class="o">=</span> <span class="n">best_p</span> <span class="o">==</span> <span class="n">P</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">best_p</span><span class="p">,</span> <span class="n">Predictor</span><span class="p">)</span> <span class="k">else</span> <span class="kc">False</span> 
            <span class="n">ax</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_fitted_curve</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">x_values</span><span class="p">,</span> <span class="n">best</span><span class="o">=</span><span class="n">best_lbl</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="n">saturation</span> <span class="o">==</span> <span class="s2">&quot;best&quot;</span><span class="p">:</span> <span class="n">saturation</span> <span class="o">=</span> <span class="n">best_p</span>

        <span class="c1"># Plot saturation</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">saturation</span><span class="p">,</span> <span class="n">Predictor</span><span class="p">):</span> 
            <span class="k">if</span> <span class="ow">not</span> <span class="n">P</span><span class="o">.</span><span class="n">diverging</span><span class="p">:</span>
                <span class="n">sat_val</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">get_saturation</span><span class="p">()</span>
                <span class="n">err</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">get_error_std</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">sat_val</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.3</span><span class="p">)</span>
                <span class="n">ax</span><span class="o">.</span><span class="n">axhspan</span><span class="p">(</span><span class="n">sat_val</span> <span class="o">-</span> <span class="n">err</span><span class="p">,</span> <span class="nb">min</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">sat_val</span> <span class="o">+</span> <span class="n">err</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>

        <span class="c1"># Plot validation of best predictor</span>
        <span class="k">if</span> <span class="n">validation</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">RMSE</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eval_fitted_curve</span><span class="p">(</span><span class="n">validation</span><span class="o">=</span><span class="n">validation</span><span class="p">,</span> <span class="n">predictor</span><span class="o">=</span><span class="n">best_p</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">label</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;Fit CV (rmse:</span><span class="si">{RMSE:.2e}</span><span class="s2">)&quot;</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">errorbar</span><span class="p">(</span><span class="n">train_sizes_val</span><span class="p">,</span> <span class="n">test_scores_mean_val</span><span class="p">,</span> <span class="n">test_scores_std_val</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_label</span><span class="p">(</span><span class="n">label</span><span class="p">),</span> <span class="n">elinewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Plot standard deviation of best predictor</span>
        <span class="k">if</span> <span class="n">uncertainty</span><span class="p">:</span>
            <span class="n">best_p</span><span class="o">.</span><span class="n">get_fit_std_params</span><span class="p">(</span><span class="n">train_sizes_val</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">max_abs</span><span class="p">)</span>
            <span class="n">y_up</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">best_p</span><span class="p">(</span><span class="n">train_sizes_val</span><span class="p">,</span> <span class="o">*</span><span class="n">best_p</span><span class="o">.</span><span class="n">params_up</span><span class="p">))</span>
            <span class="c1"># Take care to replace NaN by one in y_up and 0 in y_low</span>
            <span class="n">y_up</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">y_up</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
            <span class="n">y_low</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">nan_to_num</span><span class="p">(</span><span class="n">best_p</span><span class="p">(</span><span class="n">train_sizes_val</span><span class="p">,</span> <span class="o">*</span><span class="n">best_p</span><span class="o">.</span><span class="n">params_low</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">train_sizes_val</span><span class="p">,</span> <span class="n">y_low</span><span class="p">,</span> <span class="n">y_up</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#f1c40f&#39;</span><span class="p">)</span>

        <span class="c1"># Set limits</span>
        <span class="k">if</span> <span class="n">ylim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="n">ylim</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">xlim</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">xlim</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span> <span class="c1"># Lower right</span>
        <span class="k">if</span> <span class="n">close</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fig</span></div>


<div class="viewcode-block" id="LearningCurve.plot_fitted_curve"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.plot_fitted_curve">[docs]</a>    <span class="k">def</span> <span class="nf">plot_fitted_curve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">scores</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">best</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">best_ls</span><span class="o">=</span><span class="s1">&#39;-.&#39;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Add to figure ax a fitted curve. </span>
<span class="sd">            </span>
<span class="sd">            Args:</span>
<span class="sd">                ax (Matplotlib.axes): Figure used to print the curve.</span>
<span class="sd">                P (Predictor): Predictor to use for the computing of the curve.</span>
<span class="sd">                x (array): 1D array (list) representing the training sizes.</span>
<span class="sd">                scores (bool): Print the score of each curve fit in the legend if True.</span>
<span class="sd">                best (bool): use a higher zorder to make the curve more visible if True.</span>
<span class="sd">                best_ls (Matplotlib line-style): line-style of the curve whose Predictor is used for computing saturation accuracy.</span>
<span class="sd">                kwargs (dict): Parameters that will be forwarded to internal functions.</span>
<span class="sd">            Returns:</span>
<span class="sd">                Matplotlib axes: The updated figure.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">trialX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mi">500</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">P</span><span class="o">.</span><span class="n">score</span><span class="p">,</span><span class="mi">4</span><span class="p">)</span> <span class="k">if</span> <span class="n">P</span><span class="o">.</span><span class="n">score</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">P</span><span class="o">.</span><span class="n">name</span>
        <span class="k">if</span> <span class="n">scores</span> <span class="p">:</span> <span class="n">label</span> <span class="o">+=</span> <span class="n">f</span><span class="s2">&quot; (</span><span class="si">{score}</span><span class="s2">)&quot;</span>
        <span class="n">z</span> <span class="o">=</span> <span class="mi">3</span> <span class="k">if</span> <span class="n">best</span> <span class="k">else</span> <span class="mi">2</span>
        <span class="n">ls</span> <span class="o">=</span>  <span class="n">best_ls</span> <span class="k">if</span> <span class="n">best</span> <span class="k">else</span> <span class="s1">&#39;--&#39;</span>
        <span class="n">lw</span> <span class="o">=</span> <span class="mf">2.5</span> <span class="k">if</span> <span class="n">best</span> <span class="k">else</span> <span class="kc">None</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">trialX</span><span class="p">,</span> <span class="n">P</span><span class="p">(</span><span class="n">trialX</span><span class="p">),</span> <span class="n">ls</span><span class="o">=</span><span class="n">ls</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_label</span><span class="p">(</span><span class="n">label</span><span class="p">),</span> <span class="n">zorder</span><span class="o">=</span><span class="n">z</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="n">lw</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">ax</span></div>


<div class="viewcode-block" id="LearningCurve.compare"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.compare">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compare</span><span class="p">(</span><span class="n">lcs</span><span class="p">,</span> <span class="n">fit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">colors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">what</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Stack learning curves on a single plot (max 10).</span>
<span class="sd">        </span>
<span class="sd">            Args:</span>
<span class="sd">                lcs (list(LearningCurve)): List of LearningCurves to stack.</span>
<span class="sd">                fit (bool): If True, calls :meth:`LearningCurve.fit_all` on all the learning curve objects.</span>
<span class="sd">                figsize (tuple): Dimensions of the figure</span>
<span class="sd">                colors (cycle, list): cycle of the learning curves colors. A cycler an be created as follows: cycle = cycle(&#39;color&#39;, [&quot;color1&quot;, &quot;color2&quot;, ...])</span>
<span class="sd">                what (&quot;train&quot;, &quot;valid&quot;, &quot;both&quot;): curves to show</span>
<span class="sd">                kwargs (dict): Dictionary of values that will be passed to each :meth:`LearningCurve.plot` method</span>
<span class="sd">            Returns:</span>
<span class="sd">                fig (Matplotlib.figure): The resulting figure</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">lc</span><span class="p">,</span> <span class="n">LearningCurve</span><span class="p">)</span> <span class="k">for</span> <span class="n">lc</span> <span class="ow">in</span> <span class="n">lcs</span><span class="p">]),</span> <span class="s2">&quot;parameters must all be Predictors&quot;</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">lc</span><span class="o">.</span><span class="n">recorder</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">lc</span> <span class="ow">in</span> <span class="n">lcs</span><span class="p">]),</span> <span class="s2">&quot;All Predictors must have been trained.&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">lcs</span><span class="p">)</span><span class="o">&lt;=</span><span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;Maximum 10 learning curve object can be stacked.&quot;</span>

        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">colors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">colormap</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s2">&quot;tab20&quot;</span> <span class="k">if</span> <span class="n">what</span><span class="o">==</span><span class="s2">&quot;both&quot;</span> <span class="k">else</span> <span class="s2">&quot;tab10&quot;</span><span class="p">)</span>
            <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">colormap</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">colormap</span><span class="p">(</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span> <span class="k">if</span> <span class="n">what</span><span class="o">==</span><span class="s2">&quot;both&quot;</span> <span class="k">else</span> <span class="mi">10</span><span class="p">)]</span>
            
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span> 
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;colors must be as cycle object.&quot;</span><span class="p">)</span>

        <span class="n">cycle</span> <span class="o">=</span> <span class="n">cycler</span><span class="p">(</span><span class="s1">&#39;color&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="n">cycle</span><span class="p">)</span>  

        <span class="k">for</span> <span class="n">lc</span> <span class="ow">in</span> <span class="n">lcs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">fit</span><span class="p">:</span> <span class="n">lc</span><span class="o">.</span><span class="n">fit_all</span><span class="p">()</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">lc</span><span class="o">.</span><span class="n">plot_cust</span><span class="p">(</span><span class="n">fig</span><span class="o">=</span><span class="n">fig</span><span class="p">,</span> <span class="n">what</span><span class="o">=</span><span class="n">what</span><span class="p">,</span> <span class="o">**</span><span class="n">lc</span><span class="o">.</span><span class="n">recorder</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">fig</span></div>


<div class="viewcode-block" id="LearningCurve.get_label"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.get_label">[docs]</a>    <span class="k">def</span> <span class="nf">get_label</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Prefix the label with the name of the LearningCurve instance. </span>
<span class="sd">        </span>
<span class="sd">            Args:</span>
<span class="sd">                label (str): label to prefix</span>
<span class="sd">            Returns:</span>
<span class="sd">                label (str): label prefixed with name, if any.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">label</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">f</span><span class="s2">&quot;</span><span class="si">{self.name}</span><span class="s2"> - </span><span class="si">{label}</span><span class="s2">&quot;</span></div>


<div class="viewcode-block" id="LearningCurve.plot_time"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.plot_time">[docs]</a>    <span class="k">def</span> <span class="nf">plot_time</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">what</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">)):</span>
        <span class="sd">&quot;&quot;&quot; Plot training sizes against fit/score computing times.</span>

<span class="sd">            Args:</span>
<span class="sd">                ax (Matplotlib.axes): A figure ax on which the curves will be drawn. If None, a new one will be created.</span>
<span class="sd">                what (str): Value in [&quot;both&quot;, &quot;fit&quot;, &quot;score&quot;]. Select the curve to show.</span>
<span class="sd">                figsize (2-uple): Dimensions of the figure (ignored if ax is not None).</span>
<span class="sd">            Returns:</span>
<span class="sd">                ax (Matplotlib.axes): A Matplotlib ax of the result.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;recorder is empty. You must first compute learning curve data points using the train method.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span> 

        <span class="k">if</span> <span class="n">what</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;fit&quot;</span><span class="p">,</span> <span class="s2">&quot;both&quot;</span><span class="p">]:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;fit_times_mean&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_label</span><span class="p">(</span><span class="s2">&quot;fit&quot;</span><span class="p">))</span>
            <span class="n">lines</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;fit_times_mean&quot;</span><span class="p">])</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">],</span> 
                            <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;fit_times_mean&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;fit_times_std&quot;</span><span class="p">],</span> 
                            <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;fit_times_mean&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;fit_times_std&quot;</span><span class="p">],</span> 
                            <span class="n">color</span><span class="o">=</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_color</span><span class="p">(),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span>      

        <span class="k">if</span> <span class="n">what</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">,</span> <span class="s2">&quot;both&quot;</span><span class="p">]:</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;score_times_mean&quot;</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">get_label</span><span class="p">(</span><span class="s2">&quot;score&quot;</span><span class="p">))</span>
            <span class="n">lines</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;score_times_mean&quot;</span><span class="p">])</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;train_sizes&quot;</span><span class="p">],</span> 
                            <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;score_times_mean&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;score_times_std&quot;</span><span class="p">],</span> 
                            <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;score_times_mean&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="s2">&quot;score_times_std&quot;</span><span class="p">],</span> 
                            <span class="n">color</span><span class="o">=</span><span class="n">lines</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">get_color</span><span class="p">(),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.15</span><span class="p">)</span> 

        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Training size&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Training time (s)&quot;</span><span class="p">)</span>

        <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">ax</span></div>
    

<div class="viewcode-block" id="LearningCurve.compare_time"><a class="viewcode-back" href="../../learning_curves.html#learning_curves.learning_curves.LearningCurve.compare_time">[docs]</a>    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">compare_time</span><span class="p">(</span><span class="n">lcs</span><span class="p">,</span> <span class="n">what</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">6</span><span class="p">),</span> <span class="n">colors</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>  <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot; Stack times of the computing of the learning curves on a single plot.</span>
<span class="sd">        </span>
<span class="sd">            Args:</span>
<span class="sd">                lcs (list(LearningCurve)): List of LearningCurves to stack (max 10).</span>
<span class="sd">                what (str): Value in [&quot;both&quot;, &quot;fit&quot;, &quot;score&quot;]. Select the curve to show.</span>
<span class="sd">                figsize (tuple): Dimensions of the figure.</span>
<span class="sd">                colors (cycle, list): cycle of the learning curves colors. A cycler can be created as follows: cycle = cycle(&#39;color&#39;, [&quot;color1&quot;, &quot;color2&quot;, ...])</span>
<span class="sd">                kwargs (dict): Dictionary of values that will be passed to each :meth:`LearningCurve.plot_time` method</span>
<span class="sd">            Returns:</span>
<span class="sd">                ax (Matplotlib.axes): The resulting figure ax</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">lc</span><span class="p">,</span> <span class="n">LearningCurve</span><span class="p">)</span> <span class="k">for</span> <span class="n">lc</span> <span class="ow">in</span> <span class="n">lcs</span><span class="p">]),</span> <span class="s2">&quot;parameters must all be Predictors&quot;</span>
        <span class="k">assert</span> <span class="nb">all</span><span class="p">([</span><span class="nb">len</span><span class="p">(</span><span class="n">lc</span><span class="o">.</span><span class="n">recorder</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">lc</span> <span class="ow">in</span> <span class="n">lcs</span><span class="p">]),</span> <span class="s2">&quot;All Predictors must have been trained first.&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">lcs</span><span class="p">)</span><span class="o">&lt;=</span><span class="mi">10</span><span class="p">,</span> <span class="s2">&quot;Maximum 10 learning curve object can be stacked.&quot;</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">colors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">colormap</span> <span class="o">=</span> <span class="n">cm</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s2">&quot;tab20&quot;</span> <span class="k">if</span> <span class="n">what</span><span class="o">==</span><span class="s2">&quot;both&quot;</span> <span class="k">else</span> <span class="s2">&quot;tab10&quot;</span><span class="p">)</span>
            <span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="n">colormap</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span> <span class="k">if</span> <span class="n">what</span><span class="o">==</span><span class="s2">&quot;both&quot;</span> <span class="k">else</span> <span class="mi">10</span><span class="p">)]</span>
            
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span> 
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="s2">&quot;colors must be as cycle object.&quot;</span><span class="p">)</span>

        <span class="n">cycle</span> <span class="o">=</span> <span class="n">cycler</span><span class="p">(</span><span class="s1">&#39;color&#39;</span><span class="p">,</span> <span class="n">colors</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_prop_cycle</span><span class="p">(</span><span class="n">cycle</span><span class="p">)</span>  

        <span class="k">for</span> <span class="n">lc</span> <span class="ow">in</span> <span class="n">lcs</span><span class="p">:</span> 
            <span class="n">ax</span> <span class="o">=</span> <span class="n">lc</span><span class="o">.</span><span class="n">plot_time</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">what</span><span class="o">=</span><span class="n">what</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
            
        <span class="k">return</span> <span class="n">ax</span></div></div>
</pre></div>

           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, H4drien

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>